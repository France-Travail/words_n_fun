{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Jupyter cannot be started. Error attempting to locate jupyter: Data Science libraries jupyter and notebook are not installed in interpreter Python 3.8.0 64-bit.",
     "output_type": "error",
     "traceback": [
      "Error: Jupyter cannot be started. Error attempting to locate jupyter: Data Science libraries jupyter and notebook are not installed in interpreter Python 3.8.0 64-bit.",
      "at A.startServer (/home/neo/.vscode/extensions/ms-python.python-2020.2.64397/out/client/extension.js:1:786120)",
      "at async A.ensureServerAndNotebookImpl (/home/neo/.vscode/extensions/ms-python.python-2020.2.64397/out/client/extension.js:1:785575)",
      "at async A.ensureServerAndNotebook (/home/neo/.vscode/extensions/ms-python.python-2020.2.64397/out/client/extension.js:1:785376)",
      "at async A.submitCode (/home/neo/.vscode/extensions/ms-python.python-2020.2.64397/out/client/extension.js:1:782328)",
      "at async A.reexecuteCell (/home/neo/.vscode/extensions/ms-python.python-2020.2.64397/out/client/extension.js:75:879318)"
     ]
    }
   ],
   "source": [
    "## Notebook introducing the words_n_fun module\n",
    "# Copyright (C) <2018-2022>  <Agence Data Services, DSI Pôle Emploi>\n",
    "# \n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU Affero General Public License as\n",
    "# published by the Free Software Foundation, either version 3 of the\n",
    "# License, or (at your option) any later version.\n",
    "# \n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU Affero General Public License for more details.\n",
    "# \n",
    "# You should have received a copy of the GNU Affero General Public License\n",
    "# along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>\n",
    "\n",
    "<h2>Tutorial notebook of the preprocessing module.</h2>\n",
    "\n",
    "This notebook highlights how to use preprocessing features of the words_n_fun module on a given text corpus. \n",
    "\n",
    "**Given sample file** : Job offers sample (file csv xxx.csv)\n",
    "\n",
    "**Notebook parts** :\n",
    "<ul>\n",
    "    <li>Import required modules \n",
    "            *NB* : Don't forget the GIT  url</li>\n",
    "    <li>Import the input data :  load the csv file containing the input data  \n",
    "            *NB* : Don't forget to provide the file path</li>\n",
    "    <li>Preprocessing</li>\n",
    "        <ul>\n",
    "            <li>Extend or limit the list of stopwords with use case specific words  \n",
    "                    *NB* : Following an ad hoc analysis we can add words to the stopwords list (words that will be removed from the corpus)</li>\n",
    "            <li>Preprocessing on the corpus  \n",
    "                    As an example, we display the 3 first rows from the corpus to get a before/after picture of the data</li>\n",
    "            <li>Analysis of each preprocessing step on a sample document \n",
    "                    As an illustration, we display the resulting text after each step\n",
    "                </li>\n",
    "        </ul>\n",
    "</ul>\n",
    "\n",
    "**GIT** : TO BE DEFINED\n",
    "\n",
    "**Entrypoint** : words_n_fun.preprocessing.api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eaga7470\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tqdm\\_tqdm.py:634: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "#import the preprocessing module :\n",
    "#---------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from words_n_fun.preprocessing import api as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas \n",
    "#---------------------------------------\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the sample dataset\n",
    "\n",
    "Package xlrd is required -> pip install xlrd, then restart this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB : Don't forget to input the file path.\n",
    "dir_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "file_path = os.path.join(dir_path, \"essai1_ocr_formacodes_output.xlsx\")\n",
    "df = pd.read_excel(file_path, sheet_name='ocr_formacodes_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>titre</th>\n",
       "      <th>description</th>\n",
       "      <th>catégories</th>\n",
       "      <th>formacode 1</th>\n",
       "      <th>formacode 2</th>\n",
       "      <th>formacode 3</th>\n",
       "      <th>formacode 4</th>\n",
       "      <th>formacode 5</th>\n",
       "      <th>formacode 6</th>\n",
       "      <th>formacode 7</th>\n",
       "      <th>formacode 8</th>\n",
       "      <th>formacode 9</th>\n",
       "      <th>formacode 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19980</td>\n",
       "      <td>Apprenez à programmer en C !</td>\n",
       "      <td>Le C est un langage incontournable qui en a in...</td>\n",
       "      <td>Développement pour l'entreprise</td>\n",
       "      <td>30882.0</td>\n",
       "      <td>30854.0</td>\n",
       "      <td>31088.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26832</td>\n",
       "      <td>Apprenez à programmer en Java</td>\n",
       "      <td>Java est un langage extrêmement populaire util...</td>\n",
       "      <td>Développement pour l'entreprise</td>\n",
       "      <td>30802.0</td>\n",
       "      <td>30854.0</td>\n",
       "      <td>31088.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>43538</td>\n",
       "      <td>Reprenez le contrôle à l'aide de Linux !</td>\n",
       "      <td>Linux est un système d'exploitation qui fait t...</td>\n",
       "      <td>Systèmes et réseaux</td>\n",
       "      <td>31021.0</td>\n",
       "      <td>31032.0</td>\n",
       "      <td>31054.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                     titre  \\\n",
       "0  19980              Apprenez à programmer en C !   \n",
       "1  26832             Apprenez à programmer en Java   \n",
       "2  43538  Reprenez le contrôle à l'aide de Linux !   \n",
       "\n",
       "                                         description  \\\n",
       "0  Le C est un langage incontournable qui en a in...   \n",
       "1  Java est un langage extrêmement populaire util...   \n",
       "2  Linux est un système d'exploitation qui fait t...   \n",
       "\n",
       "                        catégories  formacode 1  formacode 2  formacode 3  \\\n",
       "0  Développement pour l'entreprise      30882.0      30854.0      31088.0   \n",
       "1  Développement pour l'entreprise      30802.0      30854.0      31088.0   \n",
       "2              Systèmes et réseaux      31021.0      31032.0      31054.0   \n",
       "\n",
       "   formacode 4  formacode 5  formacode 6  formacode 7  formacode 8  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   formacode 9  formacode 10  \n",
       "0          NaN           NaN  \n",
       "1          NaN           NaN  \n",
       "2          NaN           NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displays the first 3 rows of the dataset :\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the dataset (rows, columns) :\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The preprocessing will be applied to the \"description\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=df[\"description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here we specify the preprocessing pipeline that we'll use.</p>\n",
    "<p>These transformations will be applied in the same order in which they are specified, but \n",
    "    we can chose to apply only a subset of these (be mindful of the relevance of each step) :</p>\n",
    "<ul>\n",
    "    <li>**remove_non_string** : Removes non string characters</li>\n",
    "    \n",
    "    <li>**to_lower_except_singleletters** : Lowercase transformation except for single letters tokens (such as the R or C in R language or C language)</li>\n",
    "    <li>**remove_punct** : Returns a text without any punctuation</li>\n",
    "    <li>**remove_stopwords** :  returns a text without stopwords</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending the stopwords list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the preprocessing pipeline it is advised to **extend the stopwords list with words that are irrelevant\n",
    "for this use case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-09-20 10:33:47] - WARNING: /!\\ /!\\ /!\\: Il est conseiller d'utiliser la fonction remove_gender_synonyms avant remove_stopwords\n",
      "[2019-09-20 10:33:47] - INFO: Preprocessing: étape remove_non_string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 248/248 [00:00<00:00, 247958.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-09-20 10:33:47] - INFO: Preprocessing: étape to_lower_except_singleletters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 248/248 [00:00<00:00, 61993.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-09-20 10:33:47] - INFO: Preprocessing: étape remove_punct\n",
      "[2019-09-20 10:33:47] - INFO: Preprocessing: étape remove_stopwords\n",
      "[2019-09-20 10:33:47] - WARNING: Certains caractères sont en majuscules. Seulement les stopwords en minuscules sont supprimés\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 689/689 [00:00<00:00, 172231.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 156973.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 689/689 [00:00<00:00, 229646.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 78496.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  count\n",
       "0    0      1\n",
       "1    1      1\n",
       "2   10      3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Runs listing_count_words on the whole corpus :\n",
    "    #We can apply notnull, to_lower and remove_punct before running listing_count_words to tidy the text up\n",
    "pipeline = ['remove_non_string', 'to_lower_except_singleletters','remove_punct','remove_stopwords']\n",
    "docs_preprocess_count = preprocessing.preprocess_pipeline(docs, pipeline=pipeline)\n",
    "\n",
    "count_words=preprocessing.listing_count_words(docs_preprocess_count)\n",
    "count_words.head(3) #returns a dataFrame containig words and their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>cours</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>découvrez</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1846</td>\n",
       "      <td>web</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>509</td>\n",
       "      <td>données</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>créer</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>application</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1371</td>\n",
       "      <td>projet</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>apprenez</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949</td>\n",
       "      <td>langage</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>applications</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  count\n",
       "428          cours     92\n",
       "528      découvrez     43\n",
       "1846           web     42\n",
       "509        données     37\n",
       "440          créer     33\n",
       "117    application     29\n",
       "1371        projet     27\n",
       "131       apprenez     26\n",
       "949        langage     25\n",
       "118   applications     22"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displays the 10 most frequent words\n",
    "count_words.sort_values([\"count\"], ascending= False ).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing on the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample :\n",
    "docs=df[\"description\"][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here we define the desired pipeline.</p>\n",
    "<p>Transformations are applied in the same order in which they are specified :</p>\n",
    "<ul>\n",
    "    <li>**remove_non_string** : Removes non string characters</li>  \n",
    "    <li>**get_true_spaces** : Replaces all white spaces with a single space</li>\n",
    "        <li>**to_lower_except_singleletters** : Lower case transformation except for single letters (such as language R or language C)</li>\n",
    "        \n",
    "    <li>**pe_matching** : Basic one to one substitution \n",
    "        *Example* : \"permis b\" (french driving licence) => \"permisb\"</li>\n",
    "    <li>**remove_gender_synonyms** : Finds occurences where both male and female versions of a single words are used (eg: Serveur/Serveuse) and keep only the male version (language convention)</li>\n",
    "        \n",
    "    <li>**remove_punct_except_parenthesis** :  Removes all non alphanumeric characters by whitespaces except for parenthesis</li>\n",
    "    <li>**remove_numeric** : Returns a text without any numerical character</li>\n",
    "    <li>**remove_stopwords** : Returns a text without stopwords</li>\n",
    "    <li>**lemmatize** OU **stemmatize** : Text lemmatization or stemmatization\n",
    "    <li>**remove_accents** : Returns a text without any accent</li>\n",
    "    <li>**trim_string** : Replaces multiple white spaces by a single one</li>\n",
    "    <li>**remove_leading_and_ending_spaces** : Removes leadining and trailing white spaces</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline definition :\n",
    "pipeline = ['remove_non_string', 'get_true_spaces', 'to_lower_except_singleletters', 'pe_matching',\n",
    "                    'remove_gender_synonyms', 'remove_punct_except_parenthesis', 'remove_numeric',\n",
    "                    'remove_stopwords', 'stemmatize', 'remove_accents', 'trim_string', 'remove_leading_and_ending_spaces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the pipeline\n",
    "docs_preprocess = preprocessing.preprocess_pipeline(docs,\n",
    "                                                        pipeline=pipeline)\n",
    "docs_preprocess.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the first rows :\n",
    "for i in range(0,4) :\n",
    "    print(\"Document index n°\",i,\"before preprocessing :\")\n",
    "    print(\"'\",docs[i],\"'\")\n",
    "    print(\"  and after preprocessing \")\n",
    "    print(\"'\",docs_preprocess[i],\"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Diving into each single step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only consider the first row of our initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=docs[0]\n",
    "text=pd.Series(text)\n",
    "print(text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ['notnull', 'remove_non_string', 'to_lower_except_singleletters', 'pe_matching', 'trim_string',\n",
    "                                        'remove_gender_synonyms', 'remove_punct_except_parenthesis', 'remove_numeric',\n",
    "                                        'remove_stopwords','lemmatize', 'remove_accents']\n",
    "def preprocess_pipeline_detail(text, pipeline=pipeline):\n",
    "    print (\"Texte initial\")\n",
    "    print (text.values)\n",
    "    for item in pipeline:\n",
    "        if item in preprocessing.USAGE.keys():\n",
    "            print(\"\\n\")\n",
    "            print(str(item))\n",
    "            text=preprocessing.USAGE[item](text)\n",
    "            print (text.values)\n",
    "            #print(\"Etape %s\" % item)\n",
    "            #print(list(text.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline_detail(text,pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
